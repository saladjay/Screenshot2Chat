# Screenshot2Chat ç”¨æˆ·æŒ‡å—

## æ¬¢è¿

æ¬¢è¿ä½¿ç”¨Screenshot2Chatï¼è¿™æ˜¯ä¸€ä¸ªå¼ºå¤§çš„èŠå¤©æˆªå›¾åˆ†æåº“ï¼Œå¯ä»¥å¸®åŠ©æ‚¨ä»èŠå¤©åº”ç”¨æˆªå›¾ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚

æœ¬æŒ‡å—å°†å¸¦æ‚¨å¿«é€Ÿä¸Šæ‰‹ï¼Œå¹¶ä»‹ç»å¸¸è§çš„ä½¿ç”¨åœºæ™¯ã€‚

## ç›®å½•

- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [å®‰è£…](#å®‰è£…)
- [åŸºç¡€æ¦‚å¿µ](#åŸºç¡€æ¦‚å¿µ)
- [å¸¸è§ä½¿ç”¨åœºæ™¯](#å¸¸è§ä½¿ç”¨åœºæ™¯)
- [é…ç½®æŒ‡å—](#é…ç½®æŒ‡å—)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [FAQ](#faq)

---

## å¿«é€Ÿå¼€å§‹

### 5åˆ†é’Ÿå…¥é—¨

è®©æˆ‘ä»¬ä»ä¸€ä¸ªæœ€ç®€å•çš„ä¾‹å­å¼€å§‹ï¼š

```python
from screenshot2chat.pipeline import Pipeline
import cv2

# 1. ä»é…ç½®æ–‡ä»¶åˆ›å»ºæµæ°´çº¿
pipeline = Pipeline.from_config("config/basic_pipeline.yaml")

# 2. åŠ è½½å›¾åƒ
image = cv2.imread("my_screenshot.png")

# 3. æ‰§è¡Œåˆ†æ
results = pipeline.execute(image)

# 4. æŸ¥çœ‹ç»“æœ
print(f"æ£€æµ‹åˆ° {len(results['text_detection'])} ä¸ªæ–‡æœ¬æ¡†")
print(f"æå–çš„æ˜µç§°: {results['nickname_extraction']['data']['nicknames']}")
```

å°±è¿™ä¹ˆç®€å•ï¼æ‚¨å·²ç»å®Œæˆäº†ç¬¬ä¸€æ¬¡èŠå¤©æˆªå›¾åˆ†æã€‚

---

## å®‰è£…

### ç³»ç»Ÿè¦æ±‚

- Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- æ“ä½œç³»ç»Ÿ: Windows, macOS, Linux
- æ¨è: CUDAæ”¯æŒçš„GPUï¼ˆå¯é€‰ï¼Œç”¨äºåŠ é€Ÿï¼‰

### ä½¿ç”¨pipå®‰è£…

```bash
pip install screenshot2chat
```

### ä»æºç å®‰è£…

```bash
git clone https://github.com/your-org/screenshot2chat.git
cd screenshot2chat
pip install -e .
```

### å®‰è£…ä¾èµ–

åŸºç¡€ä¾èµ–ä¼šè‡ªåŠ¨å®‰è£…ã€‚å¦‚æœéœ€è¦ç‰¹å®šåŠŸèƒ½ï¼Œå¯ä»¥å®‰è£…é¢å¤–çš„ä¾èµ–ï¼š

```bash
# OCRæ”¯æŒ
pip install paddlepaddle paddleocr

# GPUåŠ é€Ÿ
pip install paddlepaddle-gpu

# äº‘ç«¯APIæ”¯æŒ
pip install openai anthropic
```

### éªŒè¯å®‰è£…

```python
import screenshot2chat
print(screenshot2chat.__version__)
```

---

## åŸºç¡€æ¦‚å¿µ

### æ ¸å¿ƒç»„ä»¶

Screenshot2Chatç”±ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶ç»„æˆï¼š

#### 1. Detector (æ£€æµ‹å™¨)

æ£€æµ‹å™¨è´Ÿè´£åœ¨å›¾åƒä¸­è¯†åˆ«ç‰¹å®šå…ƒç´ ï¼š

- **TextDetector**: æ£€æµ‹æ–‡æœ¬æ¡†
- **BubbleDetector**: æ£€æµ‹èŠå¤©æ°”æ³¡
- **AvatarDetector**: æ£€æµ‹å¤´åƒï¼ˆè®¡åˆ’ä¸­ï¼‰

#### 2. Extractor (æå–å™¨)

æå–å™¨ä»æ£€æµ‹ç»“æœä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ï¼š

- **NicknameExtractor**: æå–æ˜µç§°
- **SpeakerExtractor**: è¯†åˆ«è¯´è¯è€…
- **LayoutExtractor**: åˆ†æå¸ƒå±€

#### 3. Pipeline (æµæ°´çº¿)

æµæ°´çº¿å°†å¤šä¸ªæ£€æµ‹å™¨å’Œæå–å™¨ç»„åˆæˆå®Œæ•´çš„å¤„ç†æµç¨‹ã€‚

### æ•°æ®æµ

```
è¾“å…¥å›¾åƒ
  â†“
TextDetector (æ£€æµ‹æ–‡æœ¬)
  â†“
BubbleDetector (æ£€æµ‹æ°”æ³¡)
  â†“
NicknameExtractor (æå–æ˜µç§°)
  â†“
SpeakerExtractor (è¯†åˆ«è¯´è¯è€…)
  â†“
è¾“å‡ºç»“æ„åŒ–æ•°æ®
```

---

## å¸¸è§ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: åŸºç¡€æ–‡æœ¬æå–

ä»èŠå¤©æˆªå›¾ä¸­æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹ã€‚

```python
from screenshot2chat.detectors import TextDetector
import cv2

# åˆ›å»ºæ–‡æœ¬æ£€æµ‹å™¨
detector = TextDetector(backend="paddleocr")
detector.load_model()

# åŠ è½½å›¾åƒ
image = cv2.imread("chat_screenshot.png")

# æ£€æµ‹æ–‡æœ¬
results = detector.detect(image)

# æ‰“å°æ‰€æœ‰æ–‡æœ¬
for result in results:
    if result.metadata.get("text"):
        print(result.metadata["text"])
```

### åœºæ™¯2: æ˜µç§°è¯†åˆ«

è¯†åˆ«èŠå¤©æˆªå›¾ä¸­çš„ç”¨æˆ·æ˜µç§°ã€‚

```python
from screenshot2chat.pipeline import Pipeline
import cv2

# ä½¿ç”¨é¢„é…ç½®çš„æµæ°´çº¿
pipeline = Pipeline.from_config("config/nickname_pipeline.yaml")

# å¤„ç†å›¾åƒ
image = cv2.imread("chat_screenshot.png")
results = pipeline.execute(image)

# è·å–æ˜µç§°
nicknames = results["nickname_extraction"]["data"]["nicknames"]

print("è¯†åˆ«åˆ°çš„æ˜µç§°:")
for nick in nicknames:
    print(f"  - {nick['text']} (ç½®ä¿¡åº¦: {nick['nickname_score']:.1f})")
```

### åœºæ™¯3: å®Œæ•´å¯¹è¯åˆ†æ

åˆ†æå®Œæ•´çš„èŠå¤©å¯¹è¯ï¼ŒåŒ…æ‹¬è¯´è¯è€…è¯†åˆ«å’Œå¸ƒå±€åˆ†æã€‚

```python
from screenshot2chat.pipeline import Pipeline
import cv2
import json

# åˆ›å»ºå®Œæ•´åˆ†ææµæ°´çº¿
pipeline = Pipeline.from_config("config/full_analysis.yaml")

# å¤„ç†å›¾åƒ
image = cv2.imread("chat_screenshot.png")
results = pipeline.execute(image)

# æ„å»ºå¯¹è¯ç»“æ„
dialog = {
    "layout": results["layout_extraction"]["data"]["layout_type"],
    "speakers": results["speaker_extraction"]["data"]["speakers"],
    "messages": []
}

# æå–æ¶ˆæ¯
for bubble in results["bubble_detection"]:
    message = {
        "speaker": bubble.metadata.get("speaker", "unknown"),
        "text": bubble.metadata.get("text", ""),
        "bbox": bubble.bbox
    }
    dialog["messages"].append(message)

# ä¿å­˜ç»“æœ
with open("dialog_output.json", "w", encoding="utf-8") as f:
    json.dump(dialog, f, ensure_ascii=False, indent=2)

print(f"åˆ†æå®Œæˆï¼å…± {len(dialog['messages'])} æ¡æ¶ˆæ¯")
```

### åœºæ™¯4: æ‰¹é‡å¤„ç†

æ‰¹é‡å¤„ç†å¤šå¼ èŠå¤©æˆªå›¾ã€‚

```python
from screenshot2chat.pipeline import Pipeline
from pathlib import Path
import cv2
from tqdm import tqdm

# åˆ›å»ºæµæ°´çº¿
pipeline = Pipeline.from_config("config/basic_pipeline.yaml")

# è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
image_dir = Path("screenshots")
image_files = list(image_dir.glob("*.png"))

# æ‰¹é‡å¤„ç†
results_list = []
for image_path in tqdm(image_files, desc="Processing"):
    image = cv2.imread(str(image_path))
    results = pipeline.execute(image)
    results_list.append({
        "file": image_path.name,
        "results": results
    })

print(f"å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(results_list)} å¼ å›¾åƒ")
```

### åœºæ™¯5: è‡ªå®šä¹‰æµæ°´çº¿

åˆ›å»ºè‡ªå®šä¹‰çš„å¤„ç†æµæ°´çº¿ã€‚

```python
from screenshot2chat.pipeline import Pipeline, PipelineStep, StepType
from screenshot2chat.detectors import TextDetector, BubbleDetector
from screenshot2chat.extractors import NicknameExtractor, LayoutExtractor

# åˆ›å»ºç»„ä»¶
text_detector = TextDetector(backend="paddleocr")
bubble_detector = BubbleDetector(config={"screen_width": 1080})
nickname_extractor = NicknameExtractor(config={"top_k": 5})
layout_extractor = LayoutExtractor()

# æ„å»ºæµæ°´çº¿
pipeline = Pipeline(name="my_custom_pipeline")

# æ·»åŠ æ­¥éª¤
pipeline.add_step(PipelineStep(
    name="text_detection",
    step_type=StepType.DETECTOR,
    component=text_detector,
    config={"use_gpu": True}
))

pipeline.add_step(PipelineStep(
    name="bubble_detection",
    step_type=StepType.DETECTOR,
    component=bubble_detector,
    depends_on=["text_detection"]
))

pipeline.add_step(PipelineStep(
    name="nickname_extraction",
    step_type=StepType.EXTRACTOR,
    component=nickname_extractor,
    config={"source": "text_detection"}
))

pipeline.add_step(PipelineStep(
    name="layout_extraction",
    step_type=StepType.EXTRACTOR,
    component=layout_extractor,
    config={"source": "bubble_detection"}
))

# éªŒè¯æµæ°´çº¿
if pipeline.validate():
    print("æµæ°´çº¿é…ç½®æœ‰æ•ˆï¼")
    
# æ‰§è¡Œ
image = cv2.imread("screenshot.png")
results = pipeline.execute(image)
```

### åœºæ™¯6: æ€§èƒ½ç›‘æ§

ç›‘æ§å¤„ç†æ€§èƒ½ï¼Œä¼˜åŒ–æµæ°´çº¿ã€‚

```python
from screenshot2chat.pipeline import Pipeline
from screenshot2chat.monitoring import PerformanceMonitor
import cv2

# åˆ›å»ºæµæ°´çº¿å’Œç›‘æ§å™¨
pipeline = Pipeline.from_config("config/basic_pipeline.yaml")
monitor = PerformanceMonitor()

# å¤„ç†å¤šå¼ å›¾åƒ
images = [cv2.imread(f"screenshot_{i}.png") for i in range(10)]

for i, image in enumerate(images):
    monitor.start_timer(f"image_{i}")
    results = pipeline.execute(image)
    monitor.stop_timer(f"image_{i}")
    
    # è®°å½•å†…å­˜
    monitor.record_memory(f"after_image_{i}")

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
report = monitor.generate_report()
print(report)

# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = monitor.get_stats("image_0")
print(f"å¹³å‡å¤„ç†æ—¶é—´: {stats['mean']:.3f}ç§’")
print(f"æœ€å¿«: {stats['min']:.3f}ç§’")
print(f"æœ€æ…¢: {stats['max']:.3f}ç§’")
```

---

## é…ç½®æŒ‡å—

### é…ç½®æ–‡ä»¶ç»“æ„

Screenshot2Chatä½¿ç”¨YAMLæˆ–JSONæ ¼å¼çš„é…ç½®æ–‡ä»¶ã€‚

#### åŸºç¡€é…ç½®ç¤ºä¾‹ (basic_pipeline.yaml)

```yaml
name: "basic_chat_analysis"
version: "1.0"

steps:
  - name: "text_detection"
    type: "detector"
    class: "TextDetector"
    config:
      backend: "paddleocr"
      model_dir: "models/PP-OCRv5_server_det/"
      use_gpu: true
    enabled: true

  - name: "bubble_detection"
    type: "detector"
    class: "BubbleDetector"
    config:
      screen_width: 720
      memory_path: "chat_memory.json"
    depends_on: ["text_detection"]
    enabled: true

  - name: "nickname_extraction"
    type: "extractor"
    class: "NicknameExtractor"
    config:
      source: "text_detection"
      top_k: 3
      min_top_margin_ratio: 0.05
    enabled: true

output:
  format: "json"
  include_metadata: true
```

### é…ç½®ç®¡ç†

ä½¿ç”¨ConfigManagerç®¡ç†é…ç½®ï¼š

```python
from screenshot2chat.config import ConfigManager

# åˆ›å»ºé…ç½®ç®¡ç†å™¨
config = ConfigManager()

# åŠ è½½é»˜è®¤é…ç½®
config.load("config/default.yaml", layer="default")

# åŠ è½½ç”¨æˆ·é…ç½®ï¼ˆä¼šè¦†ç›–é»˜è®¤é…ç½®ï¼‰
config.load("config/user.yaml", layer="user")

# è·å–é…ç½®å€¼
backend = config.get("detector.text.backend")
threshold = config.get("detector.text.threshold", default=0.5)

# è¿è¡Œæ—¶ä¿®æ”¹é…ç½®
config.set("detector.text.use_gpu", True, layer="runtime")

# ä¿å­˜ç”¨æˆ·é…ç½®
config.save("config/user.yaml", layer="user")
```

### é…ç½®ä¼˜å…ˆçº§

é…ç½®é‡‡ç”¨ä¸‰å±‚ç»“æ„ï¼Œä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼š

1. **Runtime** (è¿è¡Œæ—¶): ç¨‹åºè¿è¡Œæ—¶åŠ¨æ€è®¾ç½®çš„é…ç½®
2. **User** (ç”¨æˆ·): ç”¨æˆ·è‡ªå®šä¹‰é…ç½®
3. **Default** (é»˜è®¤): ç³»ç»Ÿé»˜è®¤é…ç½®

---

## æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„åç«¯

æ ¹æ®æ‚¨çš„éœ€æ±‚é€‰æ‹©OCRåç«¯ï¼š

- **PaddleOCR**: æ¨èç”¨äºä¸­æ–‡å’Œå¤šè¯­è¨€åœºæ™¯ï¼Œå‡†ç¡®ç‡é«˜
- **Tesseract**: é€‚åˆè‹±æ–‡åœºæ™¯ï¼Œé€Ÿåº¦å¿«
- **EasyOCR**: æ”¯æŒå¤šç§è¯­è¨€ï¼Œæ˜“äºä½¿ç”¨

```python
# ä¸­æ–‡åœºæ™¯
detector = TextDetector(backend="paddleocr")

# è‹±æ–‡åœºæ™¯
detector = TextDetector(backend="tesseract")
```

### 2. GPUåŠ é€Ÿ

å¦‚æœæœ‰GPUï¼Œå¯ç”¨GPUåŠ é€Ÿå¯ä»¥æ˜¾è‘—æå‡æ€§èƒ½ï¼š

```yaml
config:
  use_gpu: true
  gpu_mem: 2000  # MB
```

### 3. æ‰¹é‡å¤„ç†ä¼˜åŒ–

æ‰¹é‡å¤„ç†æ—¶ï¼Œå¤ç”¨æµæ°´çº¿å®ä¾‹ï¼š

```python
# å¥½çš„åšæ³•
pipeline = Pipeline.from_config("config.yaml")
for image in images:
    results = pipeline.execute(image)

# ä¸å¥½çš„åšæ³•ï¼ˆæ¯æ¬¡éƒ½åˆ›å»ºæ–°å®ä¾‹ï¼‰
for image in images:
    pipeline = Pipeline.from_config("config.yaml")  # é¿å…è¿™æ ·åš
    results = pipeline.execute(image)
```

### 4. é”™è¯¯å¤„ç†

å§‹ç»ˆæ·»åŠ é€‚å½“çš„é”™è¯¯å¤„ç†ï¼š

```python
from screenshot2chat.core.exceptions import DetectionError, ModelLoadError

try:
    detector.load_model()
except ModelLoadError as e:
    print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    # ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
    
try:
    results = detector.detect(image)
except DetectionError as e:
    print(f"æ£€æµ‹å¤±è´¥: {e}")
    # è®°å½•é”™è¯¯å¹¶ç»§ç»­
```

### 5. æ—¥å¿—è®°å½•

ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—è®°å½•é‡è¦äº‹ä»¶ï¼š

```python
from screenshot2chat.logging import StructuredLogger

logger = StructuredLogger("my_app")
logger.set_context(user_id="12345")

logger.info("å¼€å§‹å¤„ç†å›¾åƒ", image_size=image.shape)
logger.warning("æ£€æµ‹ç½®ä¿¡åº¦è¾ƒä½", confidence=0.3)
```

---

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### é—®é¢˜1: æ¨¡å‹åŠ è½½å¤±è´¥

**é”™è¯¯ä¿¡æ¯**: `ModelLoadError: Failed to load model`

**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
2. éªŒè¯æ¨¡å‹è·¯å¾„é…ç½®æ˜¯å¦æ­£ç¡®
3. ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†…å­˜

```python
# æ£€æŸ¥æ¨¡å‹è·¯å¾„
import os
model_path = "models/PP-OCRv5_server_det/"
if not os.path.exists(model_path):
    print(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
```

#### é—®é¢˜2: æ£€æµ‹ç»“æœä¸ºç©º

**å¯èƒ½åŸå› **:
- å›¾åƒè´¨é‡å¤ªä½
- æ£€æµ‹é˜ˆå€¼è®¾ç½®è¿‡é«˜
- å›¾åƒæ ¼å¼ä¸æ”¯æŒ

**è§£å†³æ–¹æ¡ˆ**:
```python
# é™ä½æ£€æµ‹é˜ˆå€¼
config = {
    "det_db_thresh": 0.2,  # é™ä½é˜ˆå€¼
    "det_db_box_thresh": 0.3
}
detector = TextDetector(config=config)
```

#### é—®é¢˜3: å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
1. å‡å°æ‰¹å¤„ç†å¤§å°
2. é™ä½å›¾åƒåˆ†è¾¨ç‡
3. ä½¿ç”¨CPUæ¨¡å¼

```python
# è°ƒæ•´å›¾åƒå¤§å°
import cv2
image = cv2.imread("large_image.png")
image = cv2.resize(image, (720, 1280))  # ç¼©å°å›¾åƒ
```

#### é—®é¢˜4: å¤„ç†é€Ÿåº¦æ…¢

**ä¼˜åŒ–å»ºè®®**:
1. å¯ç”¨GPUåŠ é€Ÿ
2. ä½¿ç”¨æ›´å¿«çš„åç«¯
3. å‡å°‘æµæ°´çº¿æ­¥éª¤
4. æ‰¹é‡å¤„ç†

```python
# å¯ç”¨GPU
config = {"use_gpu": True}

# æˆ–ä½¿ç”¨æ›´å¿«çš„åç«¯
detector = TextDetector(backend="tesseract")
```

---

## FAQ

### Q: Screenshot2Chatæ”¯æŒå“ªäº›èŠå¤©åº”ç”¨ï¼Ÿ

A: Screenshot2Chatæ˜¯åº”ç”¨æ— å…³çš„ï¼Œå¯ä»¥å¤„ç†ä»»ä½•èŠå¤©åº”ç”¨çš„æˆªå›¾ï¼ŒåŒ…æ‹¬å¾®ä¿¡ã€WhatsAppã€Telegramã€Discordç­‰ã€‚

### Q: å¯ä»¥å¤„ç†è§†é¢‘å—ï¼Ÿ

A: ç›®å‰ä¸»è¦æ”¯æŒé™æ€å›¾åƒã€‚å¦‚æœéœ€è¦å¤„ç†è§†é¢‘ï¼Œå¯ä»¥å…ˆæå–å…³é”®å¸§ï¼Œç„¶åé€å¸§å¤„ç†ã€‚

### Q: æ”¯æŒå“ªäº›è¯­è¨€ï¼Ÿ

A: å–å†³äºæ‚¨é€‰æ‹©çš„OCRåç«¯ã€‚PaddleOCRæ”¯æŒ80+ç§è¯­è¨€ï¼ŒåŒ…æ‹¬ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ç­‰ã€‚

### Q: å¦‚ä½•æé«˜è¯†åˆ«å‡†ç¡®ç‡ï¼Ÿ

A: 
1. ä½¿ç”¨é«˜è´¨é‡çš„æˆªå›¾
2. é€‰æ‹©åˆé€‚çš„OCRåç«¯
3. è°ƒæ•´æ£€æµ‹é˜ˆå€¼
4. ä½¿ç”¨GPUåŠ é€Ÿ

### Q: å¯ä»¥åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨å—ï¼Ÿ

A: å¯ä»¥ã€‚Screenshot2Chatè®¾è®¡æ—¶è€ƒè™‘äº†ç”Ÿäº§ç¯å¢ƒçš„éœ€æ±‚ï¼ŒåŒ…æ‹¬æ€§èƒ½ç›‘æ§ã€é”™è¯¯å¤„ç†ã€æ—¥å¿—è®°å½•ç­‰ã€‚

### Q: å¦‚ä½•è´¡çŒ®ä»£ç ï¼Ÿ

A: æ¬¢è¿è´¡çŒ®ï¼è¯·æŸ¥çœ‹é¡¹ç›®çš„CONTRIBUTING.mdæ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

### Q: æœ‰å•†ä¸šæ”¯æŒå—ï¼Ÿ

A: è¯·è”ç³»é¡¹ç›®ç»´æŠ¤è€…äº†è§£å•†ä¸šæ”¯æŒé€‰é¡¹ã€‚

---

## ä¸‹ä¸€æ­¥

ç°åœ¨æ‚¨å·²ç»æŒæ¡äº†Screenshot2Chatçš„åŸºç¡€ä½¿ç”¨ï¼Œå¯ä»¥ï¼š

1. æŸ¥çœ‹[APIå‚è€ƒæ–‡æ¡£](API_REFERENCE.md)äº†è§£è¯¦ç»†çš„APIè¯´æ˜
2. é˜…è¯»[æ¶æ„æ–‡æ¡£](ARCHITECTURE.md)äº†è§£ç³»ç»Ÿè®¾è®¡
3. å‚è€ƒ[ç¤ºä¾‹ä»£ç ](../examples/)è·å–æ›´å¤šçµæ„Ÿ
4. åŠ å…¥ç¤¾åŒºè®¨è®ºï¼Œåˆ†äº«æ‚¨çš„ä½¿ç”¨ç»éªŒ

## è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. æŸ¥çœ‹æœ¬æ–‡æ¡£çš„[æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)éƒ¨åˆ†
2. æœç´¢[GitHub Issues](https://github.com/your-org/screenshot2chat/issues)
3. æäº¤æ–°çš„Issue
4. åŠ å…¥ç¤¾åŒºè®¨è®º

---

**ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼** ğŸ‰
